{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567fb9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull cdr records from db\n",
    "import psycopg2\n",
    "\n",
    "most_recent_db_scrape_datetime = None\n",
    "\n",
    "cdr_query = \"SELECT * FROM cdr_records\"\n",
    "if most_recent_db_scrape_datetime:\n",
    "    cdr_query += \"WHERE created_at >= '%s'\" % most_recent_db_scrape_datetime\n",
    "cdr_query += \";\"\n",
    "\n",
    "connection_params = {\n",
    "    \"dbname\": \"mobile_network\",\n",
    "    \"user\": \"admin\",\n",
    "    \"password\": \"admin123\",\n",
    "    \"host\": \"localhost\",\n",
    "    \"port\": 5432\n",
    "}\n",
    "conn = psycopg2.connect(**connection_params)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.execute(cdr_query)\n",
    "data = cursor.fetchall()\n",
    "\n",
    "col_names_query = \"\"\"\n",
    "SELECT column_name\n",
    "FROM information_schema.columns\n",
    "WHERE table_name = '%s';\n",
    "\"\"\"\n",
    "cursor.execute(col_names_query % 'cdr_records')\n",
    "cdr_record_cols = cursor.fetchall()\n",
    "cdr_record_cols = [item for sublist in cdr_record_cols for item in sublist]\n",
    "print(cdr_record_cols)\n",
    "\n",
    "cursor.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787c5c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(data, columns=cdr_record_cols)\n",
    "df = df.drop(['id'], axis=1)\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46e9b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and validation sets, do not shuffle because it is time-series data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "cdr_train, cdr_validate = train_test_split(df, train_size=0.8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e69cf4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def expand_time_features(my_cdr_df, time_cols):\n",
    "    def calculate_time_of_day(my_ts, time_column_name):\n",
    "        time_of_day = [0]*8 # 0-3, 3-6, 6-9, 9-12, 12-15, 15-18, 18-21, 21-24\n",
    "        # the_hour = datetime.strptime(my_ts, '%Y-%m-%d %H:%M:%S').hour\n",
    "        the_hour = my_ts.hour\n",
    "        time_of_day[the_hour // 3] = 1\n",
    "        time_bucket_cols = [time_column_name+'_time_'+str(i)+'_'+str(i+3) for i in range(0, 24, 3)]\n",
    "        return pd.Series(time_of_day, index=time_bucket_cols)\n",
    "\n",
    "    for time_col in time_cols:\n",
    "        time_buckets_df = my_cdr_df.apply(lambda row: calculate_time_of_day(row[time_col], time_col), axis=1)\n",
    "        my_cdr_df = my_cdr_df.join(time_buckets_df)\n",
    "\n",
    "    return my_cdr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf9d31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting timestamps into time-of-day categorical data\n",
    "\n",
    "cdr_train = expand_time_features(cdr_train, ['timestamp_arrival'])\n",
    "if not cdr_train['timestamp_departure'].isnull().any():\n",
    "    cdr_train = expand_time_features(cdr_train, ['timestamp_departure'])\n",
    "cdr_train = cdr_train.drop(['timestamp_arrival', 'timestamp_departure', 'created_at'], axis=1)\n",
    "cdr_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415a76aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "numerical_cols = ['user_location_x', 'user_location_y', 'distance', 'speed', 'duration']\n",
    "for col in numerical_cols:\n",
    "    cdr_train[col] = pd.to_numeric(cdr_train[col])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad9a88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "categorical_cols = ['previous_bts_id', 'bts_id', 'imei', 'mcc', 'mnc', 'lac']\n",
    "\n",
    "onehot_cols = pd.get_dummies(cdr_train[categorical_cols], prefix=categorical_cols).columns\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "cdr_train_onehot_arr = enc.fit_transform(cdr_train[categorical_cols])\n",
    "cdr_train_onehot = pd.DataFrame(cdr_train_onehot_arr.todense(), columns=onehot_cols)\n",
    "\n",
    "cdr_train = cdr_train.drop(categorical_cols, axis=1)\n",
    "cdr_train = cdr_train.join(cdr_train_onehot)\n",
    "cdr_train.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c48d797",
   "metadata": {},
   "outputs": [],
   "source": [
    "cdr_train = cdr_train.dropna(axis=1, how='all')\n",
    "\n",
    "numerical_cols = np.intersect1d(numerical_cols, cdr_train.select_dtypes(include=[np.number]).columns)\n",
    "print(numerical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbabb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "NUM_DEVIATIONS = 3\n",
    "\n",
    "# version a\n",
    "cdr_train_mean = np.mean(cdr_train[numerical_cols].to_numpy(), axis=0)\n",
    "cdr_train_std = np.std(cdr_train[numerical_cols].to_numpy(), axis=0)\n",
    "\n",
    "cdr_train_z_scores = cdr_train[numerical_cols].apply(lambda row: (row - cdr_train_mean) / cdr_train_std, axis=1)\n",
    "\n",
    "cdr_train_no_outliers = cdr_train[(np.abs(cdr_train_z_scores) < NUM_DEVIATIONS).all(axis=1)]\n",
    "cdr_train_outliers = cdr_train[(np.abs(cdr_train_z_scores) >= NUM_DEVIATIONS).any(axis=1)]\n",
    "\n",
    "# version b\n",
    "outliers = cdr_train[(np.abs(stats.zscore(cdr_train[numerical_cols])) >= NUM_DEVIATIONS).any(axis=1)]\n",
    "\n",
    "if not cdr_train_outliers.equals(outliers):\n",
    "    print(\"something's wrong with the z scores\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc7771d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cdr_train_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46188c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickleaj \n",
    "# cdr_train_mean, cdr_train_std (za racunanje cdr_validate_z_scores)\n",
    "# OneHotEncoder\n",
    "# timestamp_ [kad je zscore calculated]\n",
    "#pickle spremi u analytics/models/\n",
    "\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "data_to_save = (cdr_train_mean, cdr_train_std, enc, onehot_cols, datetime.now())\n",
    "with open('../models/cdr_analysis.pickle', 'wb') as f:\n",
    "    pickle.dump(data_to_save, f)\n",
    "\n",
    "with open('../models/cdr_validate_df.pickle', 'wb') as f:\n",
    "    pickle.dump(cdr_validate, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d403a614",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('../models/cdr_analysis.pickle', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "with open('../models/cdr_validate_df.pickle', 'rb') as f:\n",
    "    cdr_validate = pickle.load(f)\n",
    "\n",
    "cdr_train_mean, cdr_train_std, enc, onehot_cols, _ = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac2652c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'expand_time_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# prvo moram provesti iste tranformacije na cdr_validate kao sto sam napravio na cdr_train\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m cdr_validate = \u001b[43mexpand_time_features\u001b[49m(cdr_validate, [\u001b[33m'\u001b[39m\u001b[33mtimestamp_arrival\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m cdr_validate[\u001b[33m'\u001b[39m\u001b[33mtimestamp_departure\u001b[39m\u001b[33m'\u001b[39m].isnull().any():\n\u001b[32m      6\u001b[39m     cdr_validate = expand_time_features(cdr_validate, [\u001b[33m'\u001b[39m\u001b[33mtimestamp_departure\u001b[39m\u001b[33m'\u001b[39m])\n",
      "\u001b[31mNameError\u001b[39m: name 'expand_time_features' is not defined"
     ]
    }
   ],
   "source": [
    "# prvo moram provesti iste tranformacije na cdr_validate kao sto sam napravio na cdr_train\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "cdr_validate = expand_time_features(cdr_validate, ['timestamp_arrival'])\n",
    "if not cdr_validate['timestamp_departure'].isnull().any():\n",
    "    cdr_validate = expand_time_features(cdr_validate, ['timestamp_departure'])\n",
    "cdr_validate = cdr_validate.drop(['timestamp_arrival', 'timestamp_departure', 'created_at'], axis=1)\n",
    "\n",
    "\n",
    "numerical_cols = ['user_location_x', 'user_location_y', 'distance', 'speed', 'duration']\n",
    "for col in numerical_cols:\n",
    "    cdr_validate[col] = pd.to_numeric(cdr_validate[col])\n",
    "\n",
    "categorical_cols = ['previous_bts_id', 'bts_id', 'imei', 'mcc', 'mnc', 'lac']\n",
    "\n",
    "cdr_validate_onehot_arr = enc.transform(cdr_validate[categorical_cols])\n",
    "cdr_validate_onehot = pd.DataFrame(cdr_validate_onehot_arr.todense(), columns=onehot_cols)\n",
    "\n",
    "cdr_validate = cdr_validate.drop(categorical_cols, axis=1)\n",
    "cdr_validate = pd.concat([cdr_validate.reset_index(drop=True), cdr_validate_onehot.reset_index(drop=True)], axis=1)\n",
    "\n",
    "\n",
    "cdr_validate = cdr_validate.dropna(axis=1, how='all')\n",
    "\n",
    "numerical_cols = np.intersect1d(numerical_cols, cdr_validate.select_dtypes(include=[np.number]).columns)\n",
    "\n",
    "cdr_validate_z_scores = cdr_validate[numerical_cols].apply(lambda row: (row - cdr_train_mean) / cdr_train_std, axis=1)\n",
    "\n",
    "NUM_DEVIATIONS = 3\n",
    "cdr_validate_no_outliers = cdr_validate[(np.abs(cdr_validate_z_scores) < NUM_DEVIATIONS).all(axis=1)]\n",
    "cdr_validate_outliers = cdr_validate[(np.abs(cdr_validate_z_scores) >= NUM_DEVIATIONS).any(axis=1)]\n",
    "\n",
    "######################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e935be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cdr_validate"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
